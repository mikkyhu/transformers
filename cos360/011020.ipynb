{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "sys.path.append('../examples')\n",
    "sys.path.append('../jobs')\n",
    "sys.path.append('../training_data')\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from generate_with_calibration import get_lookahead_entropies\n",
    "from generate_with_entropy import sample_sequence, sample_sequence_batch, top_k_top_p_filtering\n",
    "\n",
    "import logging\n",
    "logging.getLogger('transformers.tokenization_utils').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/11/2020 11:52:55 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /u/myhu/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.085d5f6a8e7812ea05ff0e6ed0645ab2e75d80387ad55c1ad9806ee70d272f80\n",
      "01/11/2020 11:52:55 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"num_labels\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "01/11/2020 11:52:55 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /u/myhu/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n"
     ]
    }
   ],
   "source": [
    "# setup cell\n",
    "\n",
    "def set_seed(seed=42, n_gpu=0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpus = torch.cuda.device_count()\n",
    "\n",
    "set_seed()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrated_generation(file, length=100, num_samples=1, temperature=1, top_k=0, top_p=0.0):\n",
    "    ret = []\n",
    "    with open(file) as fp:\n",
    "        for line in fp:\n",
    "            context = tokenizer.encode(line)\n",
    "            context = torch.tensor(context, dtype=torch.long, device=device)\n",
    "            context = context.unsqueeze(0).repeat(num_samples, 1)\n",
    "            generated = context\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for gen_index in trange(length):\n",
    "\n",
    "                    inputs = {'input_ids': generated}\n",
    "\n",
    "                    outputs = model(**inputs)\n",
    "                    next_token_logits = outputs[0][:, -1, :] / temperature\n",
    "                    next_probs = F.softmax(next_token_logits, dim=-1)[0].detach().cpu().numpy()\n",
    "\n",
    "                    filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
    "                    next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
    "                    rank = np.argsort(next_probs)[::-1]\n",
    "                    ret.append(np.argwhere(rank == next_token.item())[0][0]) # grossly inefficient but idc anymore\n",
    "\n",
    "                    generated = torch.cat((generated, next_token), dim=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cdf = np.load('inv_cdf.npz')['inv_cdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = gaussian_kde(inv_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 43.35it/s]\n"
     ]
    }
   ],
   "source": [
    "context = \"Models of Cognition is a great class.\"\n",
    "length = 100\n",
    "\n",
    "context = tokenizer.encode(context)\n",
    "context = torch.tensor(context, dtype=torch.long, device=device)\n",
    "context = context.unsqueeze(0).repeat(1, 1)\n",
    "generated = context\n",
    "\n",
    "def sample(kde):\n",
    "    val = float('inf')\n",
    "    while val > 1.0 or val < 0.0:\n",
    "        val = kde.resample(1)[0][0]\n",
    "    return val\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in trange(length):\n",
    "        inputs = {'input_ids': generated}\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        next_token_logits = outputs[0][:, -1, :]\n",
    "        next_probs = F.softmax(next_token_logits, dim=-1)[0].detach().cpu().numpy()\n",
    "\n",
    "        rank = np.argsort(next_probs)[::-1]\n",
    "        cdf = np.cumsum(next_probs[rank])\n",
    "        val = sample(test)\n",
    "\n",
    "        vals = np.argwhere(cdf < val)\n",
    "        if vals.size == 0:\n",
    "            next_token_rank = 0\n",
    "        else:\n",
    "            next_token_rank = vals[-1][0]\n",
    "\n",
    "        next_token = torch.tensor([rank[next_token_rank]], dtype=torch.long, device=device).unsqueeze(0)\n",
    "        generated = torch.cat((generated, next_token), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "els of Cognition is a great class. It's a great class for recognizing complex states of mind. I totally agree with Matthew Davies of the Oxford Journal of Psychology and Medical Neuroscience in stating that the brain is over the moon with attention training and intermuscular competition. He obviously has long known about the advantages of attention training because recall speed is crap or hyperreflexia doesn't work. The problem is that self-report test that is very similar to SAT/ED6 also does. Sheffield experts have best theory of mind call 9\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(generated)):\n",
    "    seq = generated[j, len(context):].tolist()\n",
    "    text = tokenizer.decode(seq, clean_up_tokenization_spaces=True)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibrated_counts(file, length=100, num_samples=1):\n",
    "    ret = []\n",
    "    with open(file) as fp:\n",
    "        for line in fp:\n",
    "            context = tokenizer.encode(line)\n",
    "            context = torch.tensor(context, dtype=torch.long, device=device)\n",
    "            context = context.unsqueeze(0).repeat(num_samples, 1)\n",
    "            generated = context\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for gen_index in trange(length):\n",
    "\n",
    "                    inputs = {'input_ids': generated}\n",
    "\n",
    "                    outputs = model(**inputs)\n",
    "                    next_token_logits = outputs[0][:, -1, :]\n",
    "                    next_probs = F.softmax(next_token_logits, dim=-1)[0].detach().cpu().numpy()\n",
    "\n",
    "                    rank = np.argsort(next_probs)[::-1]\n",
    "                    cdf = np.cumsum(next_probs[rank])\n",
    "                    val = sample(test)\n",
    "\n",
    "                    vals = np.argwhere(cdf < val)\n",
    "                    if vals.size == 0:\n",
    "                        next_token_rank = 0\n",
    "                    else:\n",
    "                        next_token_rank = vals[-1][0]\n",
    "                    \n",
    "                    ret.append(next_token_rank)\n",
    "                    next_token = torch.tensor([rank[next_token_rank]], dtype=torch.long, device=device).unsqueeze(0)\n",
    "                    generated = torch.cat((generated, next_token), dim=1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../training_data/gbw/training/news1-head100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 31.36it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 31.64it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.47it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.06it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.92it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.25it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.74it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.13it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.58it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.97it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.47it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.90it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.00it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.99it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.61it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.72it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.19it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.83it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 31.30it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.55it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.88it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.03it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.97it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.52it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.43it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.67it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.84it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.87it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.10it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.73it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.08it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.33it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.77it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.96it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.46it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.97it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.56it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.42it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.48it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.84it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.18it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.46it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.90it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.49it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.19it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.01it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.57it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.17it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.14it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.96it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.18it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.76it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.25it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.32it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.44it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.29it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 30.85it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.44it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.08it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.53it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.15it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.70it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.13it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.64it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.94it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.01it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.19it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.47it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.99it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.82it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.37it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.41it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.69it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.20it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.40it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.22it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.10it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.25it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.56it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.97it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.73it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.68it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 32.03it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.31it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.17it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.26it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.45it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.82it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 29.33it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.41it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.11it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.03it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 33.99it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 31.66it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.35it/s]\n"
     ]
    }
   ],
   "source": [
    "counts_inv = get_calibrated_counts(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Inverse CDF method')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins_2 = list(range(0, 50))\n",
    "plt.hist(counts_inv, bins_2)\n",
    "plt.xlabel('Token rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Inverse CDF method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('011020_inv_cdf_token_ranks', ranks=counts_inv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
